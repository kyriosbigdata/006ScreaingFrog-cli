â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  PROYECTO: 006ScreaingFrog-cli
  DESCRIPCIÃ“N: AuditorÃ­a SEO con Screaming Frog CLI en terminal
  TECH: Screaming Frog, Shell, VM/Linux
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ ESTRUCTURA DEL PROYECTO:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  ğŸ“‚ flow/                       â†’ DocumentaciÃ³n de flujos
    â””â”€â”€ flowVM.md               â†’ Pasos para ejecutar en VM Linux
    â””â”€â”€ VM.md                   â†’ ConfiguraciÃ³n de mÃ¡quina virtual
    â””â”€â”€ mapaGeneral-proyecto.md â†’ Mapa general del proyecto


ğŸ¯ Â¿QUÃ‰ ES ESTE PROYECTO?
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Es un workflow para usar Screaming Frog SEO Spider desde lÃ­nea de 
comandos (CLI) sin interfaz grÃ¡fica. Ideal para:

  â€¢ Ejecutar auditorÃ­as SEO en servidores/VMs
  â€¢ Automatizar crawls de sitios grandes
  â€¢ Generar reportes en batch
  â€¢ Integrar en pipelines de CI/CD


ğŸš€ CÃ“MO USAR:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  1. VERIFICAR INSTALACIÃ“N:
     screamingfrogseospider --help

  2. CREAR ESTRUCTURA BASE:
     mkdir -p $HOME/sf-cli/{config,crawls,exports,logs,scripts,tmp}

  3. EJECUTAR UN CRAWL SENCILLO:
     screamingfrogseospider \
       --crawl "https://www.ejemplo.com/" \
       --headless \
       --save-crawl \
       --output-folder "$HOME/sf-cli/crawls" \
       --timestamped-output

  4. VER RESULTADOS:
     cd $(ls -td $HOME/sf-cli/crawls/* | head -1)
     ls -la


âš™ï¸ CONFIGURACIÃ“N DEL ENTORNO:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  â€¢ Sistema: Linux / VM (Ubuntu recomendado)
  â€¢ Requisito: Screaming Frog SEO Spider CLI instalado
  â€¢ Permisos: Acceso a terminal con permisos de ejecuciÃ³n


ğŸ“‹ PARÃMETROS PRINCIPALES CLI:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  --crawl "URL"                 â†’ URL a auditar
  --headless                    â†’ Ejecutar sin interfaz grÃ¡fica
  --save-crawl                  â†’ Guardar archivo de crawl
  --output-folder "ruta"        â†’ Carpeta de salida
  --timestamped-output          â†’ Agregar timestamp a salida
  --bulk-export "tipo"          â†’ Exportar formato especÃ­fico
  --user-agent "agent"          â†’ Cambiar user agent
  --timeout N                   â†’ Timeout en segundos
  --max-pages N                 â†’ MÃ¡ximo de pÃ¡ginas a crawlear


ğŸ“‚ ESTRUCTURA DE CARPETAS GENERADAS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  $HOME/sf-cli/
  â”œâ”€â”€ config/        â†’ Archivos de configuraciÃ³n
  â”œâ”€â”€ crawls/        â†’ Resultados de auditorÃ­as (timestamped)
  â”‚   â””â”€â”€ 2025.11.19.17.43.39/
  â”‚       â”œâ”€â”€ [datos de crawl]
  â”‚       â”œâ”€â”€ [reportes]
  â”œâ”€â”€ exports/       â†’ Exportaciones procesadas
  â”œâ”€â”€ logs/          â†’ Logs de ejecuciÃ³n
  â”œâ”€â”€ scripts/       â†’ Scripts bash para automatizar
  â””â”€â”€ tmp/           â†’ Archivos temporales


ğŸ’¡ EJEMPLOS DE COMANDOS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  # Crawl bÃ¡sico con timestamp
  screamingfrogseospider --crawl "https://ejemplo.com" --headless \
    --output-folder "$HOME/sf-cli/crawls" --timestamped-output

  # Crawl con lÃ­mite de pÃ¡ginas
  screamingfrogseospider --crawl "https://ejemplo.com" --headless \
    --max-pages 1000 --output-folder "$HOME/sf-cli/crawls"

  # Ver carpeta mÃ¡s reciente
  cd $(ls -td $HOME/sf-cli/crawls/* | head -1)

  # Listar contenido detallado
  ls -lah


ğŸ“ DOCUMENTACIÃ“N INCLUIDA:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  flowVM.md
    â†’ Pasos paso a paso para ejecutar en una VM
    â†’ Comandos especÃ­ficos y verificaciones
  
  VM.md
    â†’ ConfiguraciÃ³n de mÃ¡quina virtual
    â†’ Requisitos de sistema
    â†’ InstalaciÃ³n de Screaming Frog CLI
  
  mapaGeneral-proyecto.md
    â†’ VisiÃ³n general del proyecto
    â†’ Flujos de trabajo
    â†’ Objetivos


âœ… FLUJO TÃPICO:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  1. Verificar instalaciÃ³n (--help)
  
  2. Crear directorios base
  
  3. Ejecutar crawl con --headless
  
  4. Guardar automÃ¡ticamente con --timestamped-output
  
  5. Procesar resultados desde carpeta generada


âš ï¸ NOTAS IMPORTANTES:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  â€¢ Requiere licencia activa de Screaming Frog
  
  â€¢ Ideal ejecutarse en Linux/VM por eficiencia
  
  â€¢ --headless es imprescindible en servidores sin GUI
  
  â€¢ --timestamped-output evita sobrescribir resultados
  
  â€¢ AuditorÃ­as grandes pueden tardar horas (ajustar --max-pages)
  
  â€¢ Los logs se guardan en la carpeta de salida


ğŸ”— REFERENCIAS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  â€¢ DocumentaciÃ³n Screaming Frog:
    https://www.screamingfrog.co.uk/

  â€¢ CLI guÃ­a oficial:
    https://www.screamingfrog.co.uk/seo-spider/user-guide/


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
